{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b8bbcf",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running the first cell, make sure you're authenticated with Azure CLI. Run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "az login\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```bash\n",
    "az login --use-device-code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f268b0a",
   "metadata": {},
   "source": [
    "# Azure AI Agent with Existing Thread Example\n",
    "\n",
    "This notebook demonstrates working with pre-existing conversation threads by providing thread IDs for thread reuse patterns.\n",
    "\n",
    "## Features Covered:\n",
    "- Creating and managing persistent conversation threads\n",
    "- Working with existing thread IDs\n",
    "- Thread lifecycle management (create, use, delete)\n",
    "- Conversation continuity across sessions\n",
    "- Thread initialization and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d30a3a",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. **Azure AI Project**: Access to an Azure AI Foundry project with deployed models\n",
    "2. **Authentication**: Azure CLI installed and authenticated (`az login --use-device-code`)\n",
    "3. **Environment Variables**: Set up your `.env` file with connection details\n",
    "4. **Dependencies**: Required agent-framework packages installed\n",
    "\n",
    "If you need to use a different tenant, specify the tenant ID:\n",
    "```bash\n",
    "az login --tenant <tenant-id>\n",
    "```\n",
    "\n",
    "This example demonstrates how to work with existing threads to maintain conversation continuity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d28ee6d",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import the required libraries for Azure AI agent functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f6a607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from azure.identity import AzureCliCredential, InteractiveBrowserCredential\n",
    "from dotenv import load_dotenv  # For loading environment variables from .env file\n",
    "import asyncio\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from pydantic import Field\n",
    "\n",
    "# Get the path to the .env file which is in the parent directory\n",
    "notebook_path = Path().absolute()  # Get absolute path of current notebook\n",
    "parent_dir = notebook_path.parent  # Get parent directory\n",
    "load_dotenv('../../.env')  # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdf0eab",
   "metadata": {},
   "source": [
    "## Check Environment Variables\n",
    "\n",
    "Let's verify that the required environment variables are set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792db510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AZURE_AI_PROJECT_ENDPOINT: https://demopocaifoundry.services.ai.azure.com/api/projects/demoproject\n"
     ]
    }
   ],
   "source": [
    "# Check required environment variables\n",
    "endpoint = os.getenv('AZURE_AI_PROJECT_ENDPOINT')\n",
    "if endpoint:\n",
    "    print(f\"‚úÖ AZURE_AI_PROJECT_ENDPOINT: {endpoint}\")\n",
    "else:\n",
    "    print(\"‚ùå AZURE_AI_PROJECT_ENDPOINT: Not set\")\n",
    "    print(\"‚ö†Ô∏è  Please set the AZURE_AI_PROJECT_ENDPOINT environment variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf80a6",
   "metadata": {},
   "source": [
    "## Define Function Tools\n",
    "\n",
    "Let's define a simple weather function that our agent can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ef2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}¬∞C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9e916",
   "metadata": {},
   "source": [
    "## Create and Use Existing Thread\n",
    "\n",
    "This example shows how to:\n",
    "1. Create a thread that persists beyond the current session\n",
    "2. Use the thread ID to continue conversations\n",
    "3. Properly clean up thread resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afe62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    print(\"=== Azure AI Chat Client with Existing Thread ===\")\n",
    "\n",
    "    # Create the client\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AIProjectClient(endpoint=os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"], credential=credential) as client,\n",
    "    ):\n",
    "        # Create a thread that will persist\n",
    "        created_thread = await client.agents.threads.create()\n",
    "        print(f\"‚úÖ Created thread with ID: {created_thread.id}\")\n",
    "\n",
    "        try:\n",
    "            async with ChatAgent(\n",
    "                # passing in the client is optional here, so if you take the agent_id from the portal\n",
    "                # you can use it directly without the two lines above.\n",
    "                chat_client=AzureAIAgentClient(project_client=client, async_credential=credential),\n",
    "                instructions=\"You are a helpful weather agent.\",\n",
    "                tools=get_weather,\n",
    "            ) as agent:\n",
    "                thread = agent.get_new_thread(service_thread_id=created_thread.id)\n",
    "                assert thread.is_initialized\n",
    "                print(f\"‚úÖ Thread is initialized: {thread.is_initialized}\")\n",
    "                \n",
    "                result = await agent.run(\"What's the weather like in Tokyo?\", thread=thread)\n",
    "                print(f\"Result: {result}\\n\")\n",
    "        finally:\n",
    "            # Clean up the thread manually\n",
    "            await client.agents.threads.delete(created_thread.id)\n",
    "            print(f\"üóëÔ∏è  Deleted thread with ID: {created_thread.id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2244be0",
   "metadata": {},
   "source": [
    "## Execute the Example\n",
    "\n",
    "Run the main function to see the existing thread workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1cd7596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure AI Chat Client with Existing Thread ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:52:10 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created thread with ID: thread_LyxJzOPenVdozx5g3sKeKEee\n",
      "‚úÖ Thread is initialized: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:52:13 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: The weather in Tokyo is currently stormy with a high temperature of 25¬∞C. Stay cautious and prepared for stormy conditions!\n",
      "\n",
      "üóëÔ∏è  Deleted thread with ID: thread_LyxJzOPenVdozx5g3sKeKEee\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2e5b5a",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversation Example\n",
    "\n",
    "This example shows how to have a multi-turn conversation using a persistent thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d1202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multi-Turn Conversation Example ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:52:43 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Started conversation with thread ID: thread_igU8m87q7bmkgNgDykMCcrup\n",
      "\n",
      "--- Turn 1 ---\n",
      "ü§î User: What's the weather like in Paris?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:52:46 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n",
      "[2026-02-12 11:52:50 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: The weather in Paris is sunny, with a high temperature of 30¬∞C.\n",
      "\n",
      "--- Turn 2 ---\n",
      "ü§î User: How about in London?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:52:53 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n",
      "[2026-02-12 11:52:55 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: The weather in London is sunny, with a high of 23¬∞C.\n",
      "\n",
      "--- Turn 3 ---\n",
      "ü§î User: Which city has better weather between the two I just asked about?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:52:59 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: Both cities have sunny weather today, but Paris is warmer with a high of 30¬∞C compared to London's 23¬∞C. If you prefer warmer temperatures, Paris has the better weather!\n",
      "\n",
      "--- Turn 4 ---\n",
      "ü§î User: Thank you for the information about Paris and London.\n",
      "ü§ñ Agent: You're very welcome! Let me know if you need more weather updates or have any other questions. Have a great day! ‚òÄÔ∏è\n",
      "\n",
      "üóëÔ∏è  Conversation ended. Deleted thread: thread_igU8m87q7bmkgNgDykMCcrup\n"
     ]
    }
   ],
   "source": [
    "async def multi_turn_conversation_example():\n",
    "    \"\"\"Example showing multi-turn conversation with persistent thread.\"\"\"\n",
    "    print(\"=== Multi-Turn Conversation Example ===\")\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AIProjectClient(endpoint=os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"], credential=credential) as client,\n",
    "    ):\n",
    "        # Create a persistent thread for the conversation\n",
    "        conversation_thread = await client.agents.threads.create()\n",
    "        print(f\"üìù Started conversation with thread ID: {conversation_thread.id}\")\n",
    "        \n",
    "        try:\n",
    "            async with ChatAgent(\n",
    "                chat_client=AzureAIAgentClient(project_client=client, async_credential=credential),\n",
    "                instructions=\"You are a helpful weather agent. Remember previous conversations and provide contextual responses.\",\n",
    "                tools=get_weather,\n",
    "            ) as agent:\n",
    "                \n",
    "                # Get the thread object\n",
    "                thread = agent.get_new_thread(service_thread_id=conversation_thread.id)\n",
    "                \n",
    "                # Multi-turn conversation\n",
    "                conversation = [\n",
    "                    \"What's the weather like in Paris?\",\n",
    "                    \"How about in London?\",\n",
    "                    \"Which city has better weather between the two I just asked about?\",\n",
    "                    \"Thank you for the information about Paris and London.\"\n",
    "                ]\n",
    "                \n",
    "                for i, user_message in enumerate(conversation, 1):\n",
    "                    print(f\"\\n--- Turn {i} ---\")\n",
    "                    print(f\"ü§î User: {user_message}\")\n",
    "                    \n",
    "                    result = await agent.run(user_message, thread=thread)\n",
    "                    print(f\"ü§ñ Agent: {result.text}\")\n",
    "                    \n",
    "        finally:\n",
    "            # Clean up the thread\n",
    "            await client.agents.threads.delete(conversation_thread.id)\n",
    "            print(f\"\\nüóëÔ∏è  Conversation ended. Deleted thread: {conversation_thread.id}\")\n",
    "\n",
    "# Run the multi-turn conversation example\n",
    "await multi_turn_conversation_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa50682",
   "metadata": {},
   "source": [
    "## Thread Management Example\n",
    "\n",
    "This example demonstrates advanced thread management operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc999d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Thread Management Example ===\n",
      "üìù Created thread 1: thread_KDCHPPJXAlh8XJjF0X3bBTiR\n",
      "üìù Created thread 2: thread_t6qNrFa2bTFZv2m2DBB9hd5u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:53:22 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Created thread 3: thread_RjSkqoPMs6ogw9QVmtsZeU3F\n",
      "\n",
      "--- Thread 1: Weather in New York ---\n",
      "ü§î User: What's the weather in New York?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:53:25 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n",
      "[2026-02-12 11:53:27 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: The weather in New York is rainy with a high of 11¬∞C.\n",
      "\n",
      "--- Thread 2: Weather in Berlin ---\n",
      "ü§î User: How's the weather in Berlin?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:53:30 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n",
      "[2026-02-12 11:53:32 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: The weather in Berlin is sunny with a high of 26¬∞C.\n",
      "\n",
      "--- Thread 3: Weather comparison ---\n",
      "ü§î User: Compare weather in Asia vs Europe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-12 11:53:35 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n",
      "[2026-02-12 11:53:38 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: Currently, in Asia, the weather is stormy with a high of 26¬∞C, while in Europe, it is rainy with a high of 17¬∞C. It appears Asia is warmer but experiencing stormier conditions compared to Europe.\n",
      "\n",
      "--- Following up on Thread 1 ---\n",
      "ü§î User: Is it good weather for outdoor activities?\n",
      "ü§ñ Agent: Since the weather is rainy in New York and has a high of 11¬∞C, it might not be the best for outdoor activities. Rain can make conditions wet and slippery, and cooler temperatures may not be ideal for comfort. If you're planning to be outdoors, remember to dress warmly and bring rain gear. Alternatively, it might be a good day for indoor activities!\n",
      "üóëÔ∏è  Deleted thread 1: thread_KDCHPPJXAlh8XJjF0X3bBTiR\n",
      "üóëÔ∏è  Deleted thread 2: thread_t6qNrFa2bTFZv2m2DBB9hd5u\n",
      "üóëÔ∏è  Deleted thread 3: thread_RjSkqoPMs6ogw9QVmtsZeU3F\n"
     ]
    }
   ],
   "source": [
    "async def thread_management_example():\n",
    "    \"\"\"Advanced example showing thread management operations.\"\"\"\n",
    "    print(\"=== Thread Management Example ===\")\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AIProjectClient(endpoint=os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"], credential=credential) as client,\n",
    "    ):\n",
    "        # Create multiple threads\n",
    "        threads = []\n",
    "        for i in range(3):\n",
    "            thread = await client.agents.threads.create()\n",
    "            threads.append(thread)\n",
    "            print(f\"üìù Created thread {i+1}: {thread.id}\")\n",
    "        \n",
    "        try:\n",
    "            async with ChatAgent(\n",
    "                chat_client=AzureAIAgentClient(project_client=client, async_credential=credential),\n",
    "                instructions=\"You are a helpful assistant. Each thread represents a different conversation.\",\n",
    "                tools=get_weather,\n",
    "            ) as agent:\n",
    "                \n",
    "                # Use each thread for a different topic\n",
    "                topics = [\n",
    "                    (\"Weather in New York\", \"What's the weather in New York?\"),\n",
    "                    (\"Weather in Berlin\", \"How's the weather in Berlin?\"),\n",
    "                    (\"Weather comparison\", \"Compare weather in Asia vs Europe\")\n",
    "                ]\n",
    "                \n",
    "                for i, (topic, query) in enumerate(topics):\n",
    "                    print(f\"\\n--- Thread {i+1}: {topic} ---\")\n",
    "                    thread_obj = agent.get_new_thread(service_thread_id=threads[i].id)\n",
    "                    \n",
    "                    print(f\"ü§î User: {query}\")\n",
    "                    result = await agent.run(query, thread=thread_obj)\n",
    "                    print(f\"ü§ñ Agent: {result.text}\")\n",
    "                    \n",
    "                # Follow up on first thread to show conversation continuity\n",
    "                print(\"\\n--- Following up on Thread 1 ---\")\n",
    "                thread_1 = agent.get_new_thread(service_thread_id=threads[0].id)\n",
    "                followup = \"Is it good weather for outdoor activities?\"\n",
    "                print(f\"ü§î User: {followup}\")\n",
    "                result = await agent.run(followup, thread=thread_1)\n",
    "                print(f\"ü§ñ Agent: {result.text}\")\n",
    "                \n",
    "        finally:\n",
    "            # Clean up all threads\n",
    "            for i, thread in enumerate(threads):\n",
    "                await client.agents.threads.delete(thread.id)\n",
    "                print(f\"üóëÔ∏è  Deleted thread {i+1}: {thread.id}\")\n",
    "\n",
    "# Run the thread management example\n",
    "await thread_management_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912623de",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Persistent Threads**: Threads can persist beyond a single session, enabling conversation continuity\n",
    "2. **Thread Initialization**: Always verify that threads are properly initialized before use\n",
    "3. **Conversation Context**: Threads maintain conversation history, allowing for contextual responses\n",
    "4. **Resource Management**: Always clean up threads when they're no longer needed\n",
    "5. **Multi-Threading**: You can manage multiple separate conversations using different thread IDs\n",
    "6. **Thread Reuse**: Threads can be reused across different agent instances\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Thread Lifecycle**: Create threads when starting conversations and delete them when finished\n",
    "2. **Error Handling**: Use try-finally blocks to ensure thread cleanup\n",
    "3. **Thread Validation**: Always check if threads are initialized before using them\n",
    "4. **Context Awareness**: Leverage thread history for more contextual conversations\n",
    "5. **Resource Monitoring**: Monitor thread usage to avoid unnecessary resource consumption\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "- **Customer Support**: Maintaining conversation history across support sessions\n",
    "- **Multi-Session Chats**: Continuing conversations across different user sessions\n",
    "- **Conversation Branching**: Managing multiple conversation topics simultaneously\n",
    "- **Context Preservation**: Keeping conversation context for better user experience\n",
    "- **Session Management**: Managing different conversation sessions for different users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
