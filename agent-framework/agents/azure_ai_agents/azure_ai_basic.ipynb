{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53acc899",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running the first cell, make sure you're authenticated with Azure CLI. Run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "az login\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```bash\n",
    "az login --use-device-code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8909d",
   "metadata": {},
   "source": [
    "# Azure AI Agent Basic Example\n",
    "\n",
    "This notebook demonstrates basic usage of AzureAIAgentClient to create agents with automatic lifecycle management. It shows both streaming and non-streaming responses with function tools.\n",
    "\n",
    "## Features Covered:\n",
    "- Creating an Azure AI Agent with automatic lifecycle management\n",
    "- Using function tools (weather function)\n",
    "- Non-streaming responses (get complete result at once)\n",
    "- Streaming responses (get results as they are generated)\n",
    "- Authentication using Azure CLI credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb53f4",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have:\n",
    "1. Installed the agent-framework packages\n",
    "2. Authenticated with Azure CLI (`az login --use-device-code`)\n",
    "3. Configured your Azure AI services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47fa9b",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary libraries and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c87dfd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "\n",
    "import asyncio\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from pydantic import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb95fd4",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "We'll start by importing needed libraries, loading environment variables, and initializing an **AIProjectClient** so we can do all the agent-related actions. Let's do it! ðŸŽ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37198f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Project Endpoint: https://demopocaifoundry.services.ai.azure.com/api/projects/demoproject\n",
      "ðŸ¤– Model Deployment: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path  # For working with file paths\n",
    "import os  # For environment variables\n",
    "from dotenv import load_dotenv  # For loading environment variables from .env file\n",
    "\n",
    "# Get the path to the .env file which is in the parent directory\n",
    "notebook_path = Path().absolute()  # Get absolute path of current notebook\n",
    "parent_dir = notebook_path.parent  # Get parent directory\n",
    "load_dotenv('../../.env')  # Load environment variables from .env file\n",
    "\n",
    "# Get configuration from environment variables\n",
    "project_endpoint = os.environ.get(\"AI_FOUNDRY_PROJECT_ENDPOINT\")\n",
    "model_deployment = os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "\n",
    "# Validate and clean endpoint (remove any inline comments)\n",
    "if project_endpoint and '#' in project_endpoint:\n",
    "    print(\"âš ï¸  WARNING: Endpoint contains a '#' character - cleaning it...\")\n",
    "    project_endpoint = project_endpoint.split('#')[0].strip()\n",
    "\n",
    "print(f\"ðŸ”— Project Endpoint: {project_endpoint}\")\n",
    "print(f\"ðŸ¤– Model Deployment: {model_deployment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bb514",
   "metadata": {},
   "source": [
    "## Define Function Tools\n",
    "\n",
    "Function tools allow the agent to call specific functions to gather information or perform actions. Here we define a simple weather function that the agent can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b074eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}Â°C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1a9e8",
   "metadata": {},
   "source": [
    "## Non-Streaming Response Example\n",
    "\n",
    "In this example, we'll create an agent and get a complete response at once (non-streaming). The agent will be automatically created and deleted after getting the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a90633",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def non_streaming_example() -> None:\n",
    "    \"\"\"Example of non-streaming response (get the complete result at once).\"\"\"\n",
    "    print(\"=== Non-streaming Response Example ===\")\n",
    "\n",
    "    # Configure the client with your Azure AI Foundry project endpoint and model\n",
    "    # The agent will be automatically created and deleted after getting a response\n",
    "    # For authentication, run `az login` command in terminal\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(\n",
    "            async_credential=credential,\n",
    "            project_endpoint=project_endpoint,  # âœ… Connects to your Foundry project\n",
    "            model_deployment_name=model_deployment  # âœ… Uses your deployed model\n",
    "        ).create_agent(\n",
    "            name=\"WeatherAgent\",\n",
    "            instructions=\"You are a helpful weather agent.\",\n",
    "            tools=get_weather,\n",
    "        ) as agent,\n",
    "    ):\n",
    "        query = \"What's the weather like in Seattle?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Agent: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d857ca",
   "metadata": {},
   "source": [
    "## Streaming Response Example\n",
    "\n",
    "In this example, we'll demonstrate streaming responses where we get results as they are generated by the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019a53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def streaming_example() -> None:\n",
    "    \"\"\"Example of streaming response (get results as they are generated).\"\"\"\n",
    "    print(\"=== Streaming Response Example ===\")\n",
    "\n",
    "    # Configure the client with your Azure AI Foundry project endpoint and model\n",
    "    # The agent will be automatically created and deleted after getting a response\n",
    "    # For authentication, run `az login` command in terminal\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(\n",
    "            async_credential=credential,\n",
    "            project_endpoint=project_endpoint,  # âœ… Connects to your Foundry project\n",
    "            model_deployment_name=model_deployment  # âœ… Uses your deployed model\n",
    "        ).create_agent(\n",
    "            name=\"WeatherAgent\",\n",
    "            instructions=\"You are a helpful weather agent.\",\n",
    "            tools=get_weather,\n",
    "        ) as agent,\n",
    "    ):\n",
    "        query = \"What's the weather like in Portland?\"\n",
    "        print(f\"User: {query}\")\n",
    "        print(\"Agent: \", end=\"\", flush=True)\n",
    "        async for chunk in agent.run_stream(query):\n",
    "            if chunk.text:\n",
    "                print(chunk.text, end=\"\", flush=True)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb42e74",
   "metadata": {},
   "source": [
    "## Main Execution Function\n",
    "\n",
    "This function orchestrates the execution of both examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b61963",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    print(\"=== Basic Azure AI Chat Client Agent Example ===\")\n",
    "\n",
    "    await non_streaming_example()\n",
    "    await streaming_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1225c4c",
   "metadata": {},
   "source": [
    "## Run the Examples\n",
    "\n",
    "Execute the main function to run both streaming and non-streaming examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f76b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Azure AI Chat Client Agent Example ===\n",
      "=== Non-streaming Response Example ===\n",
      "User: What's the weather like in Seattle?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-31 15:06:56 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: The weather in Seattle is sunny with a high of 18Â°C (64Â°F). Enjoy the beautiful day!\n",
      "\n",
      "=== Streaming Response Example ===\n",
      "User: What's the weather like in Portland?\n",
      "Agent: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-31 15:07:07 - c:\\src\\ai-foundry-e2e-lab\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:704 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Portland is sunny with a high of 18Â°C. Enjoy your day!\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e3849",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Automatic Lifecycle Management**: When no Agent ID is provided, the agent is automatically created and cleaned up\n",
    "2. **Function Tools**: Agents can use custom functions to perform specific tasks (like getting weather data)\n",
    "3. **Authentication**: Uses Azure CLI credentials for authentication (make sure to run `az login` first)\n",
    "4. **Response Types**: \n",
    "   - Non-streaming: Get complete response at once using `agent.run()`\n",
    "   - Streaming: Get response chunks as they're generated using `agent.run_stream()`\n",
    "5. **Context Managers**: Using `async with` ensures proper resource cleanup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
