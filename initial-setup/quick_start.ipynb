{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e86a0d",
   "metadata": {},
   "source": [
    "# Quick Start Guide - Azure AI Foundry\n",
    "\n",
    "This notebook provides a hands-on introduction to Azure AI Foundry. You'll learn how to:\n",
    "1. Initialize the AI Project client\n",
    "2. List available models\n",
    "3. Create a simple chat completion request\n",
    "4. Create a basic AI agent\n",
    "5. Handle basic error scenarios\n",
    "\n",
    "## Prerequisites\n",
    "- Completed environment setup from previous notebook\n",
    "- Azure credentials configured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b65a7d",
   "metadata": {},
   "source": [
    "## Import Required Libraries and Setup\n",
    "\n",
    "In the next cell, we'll:\n",
    "1. Import the necessary Azure SDK libraries for authentication and AI Projects\n",
    "2. Import standard Python libraries for environment variables and JSON handling\n",
    "3. Initialize Azure credentials using DefaultAzureCredential\n",
    "   - This will automatically use your logged-in Azure CLI credentials\n",
    "   - Alternatively, it can use other authentication methods like environment variables or managed identity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a355de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Using Tenant ID: 16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "‚úÖ Successfully initialized Azure credentials with correct tenant!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, AzureCliCredential, InteractiveBrowserCredential, ChainedTokenCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize credentials with tenant-specific authentication (same as environment setup)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Get the correct tenant ID from environment\n",
    "correct_tenant_id = os.getenv(\"TENANT_ID\")\n",
    "print(f\"üîë Using Tenant ID: {correct_tenant_id}\")\n",
    "\n",
    "# Create a credential chain with tenant-specific authentication\n",
    "def create_credential_chain_with_tenant():\n",
    "    \"\"\"Create a robust credential chain for authentication with specific tenant\"\"\"\n",
    "    try:\n",
    "        # Try Azure CLI first with the specific tenant\n",
    "        cli_credential = AzureCliCredential(tenant_id=correct_tenant_id)\n",
    "        \n",
    "        # Create a chained credential with fallbacks, all using the correct tenant\n",
    "        credential_chain = ChainedTokenCredential(\n",
    "            cli_credential,\n",
    "            InteractiveBrowserCredential(tenant_id=correct_tenant_id)\n",
    "        )\n",
    "        \n",
    "        return credential_chain\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Credential chain creation error: {e}\")\n",
    "        # Fallback to DefaultAzureCredential with tenant specified\n",
    "        return DefaultAzureCredential(tenant_id=correct_tenant_id)\n",
    "\n",
    "# Initialize credentials\n",
    "try:\n",
    "    credential = create_credential_chain_with_tenant()\n",
    "    \n",
    "    # Test the credential by getting a token for the correct tenant\n",
    "    test_token = credential.get_token(\"https://management.azure.com/.default\")\n",
    "    print(\"‚úÖ Successfully initialized Azure credentials with correct tenant!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Credential initialization failed: {str(e)}\")\n",
    "    print(f\"üí° Please run the authentication fix from the environment setup notebook first\")\n",
    "    credential = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18d4ef",
   "metadata": {},
   "source": [
    "## Initialize AI Project Client\n",
    "\n",
    "> **Note:** Before proceeding, ensure you:\n",
    "> 1. Copy your `.env.example` file to `.env` from the root directory\n",
    "> 2. Update the project endpoint in your `.env` file\n",
    "> 3. Have a Foundry Project already provisioned in Azure AI Foundry\n",
    "\n",
    "You can find your project endpoint in [Azure AI Foundry](https://ai.azure.com) under your project's settings:\n",
    "\n",
    "<img src=\"../images/foundry-endpoint.png\" alt=\"Project Endpoint Location\" width=\"75%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5ebd2",
   "metadata": {},
   "source": [
    "## Creating the AI Project Client\n",
    "\n",
    "In the next cell, we'll create an AI Project client using the connection string from our `.env` file.\n",
    "> **Note:** This example uses the synchronous client. For higher performance scenarios, you can also create an asynchronous client by importing `asyncio` and using the async methods from `AIProjectClient`.\n",
    "\n",
    "The client will be used to:\n",
    "- Connect to your Azure AI Project using the connection string\n",
    "- Authenticate using Azure credentials\n",
    "- Enable making inference requests to your deployed models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b96006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Project Endpoint: https://demopocaifoundry.services.ai.azure.com/api/projects/demoproject\n",
      "‚úì Successfully initialized AIProjectClient\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables\n",
    "notebook_path = Path().absolute()\n",
    "parent_dir = notebook_path.parent\n",
    "load_dotenv(parent_dir / '.env')\n",
    "\n",
    "try:\n",
    "    # Get the project connection string (which is actually the endpoint URL)\n",
    "    project_endpoint = os.getenv(\"AI_FOUNDRY_PROJECT_ENDPOINT\")\n",
    "    if not project_endpoint:\n",
    "        raise ValueError(\"AI_FOUNDRY_PROJECT_ENDPOINT not found in environment variables\")\n",
    "\n",
    "    print(f\"üîó Project Endpoint: {project_endpoint}\")\n",
    "\n",
    "    # Create AIProjectClient as done in environment_setup (consistent with other notebooks)\n",
    "    client = AIProjectClient(\n",
    "        credential=credential,\n",
    "        endpoint=project_endpoint\n",
    "    )\n",
    "    print(\"‚úì Successfully initialized AIProjectClient\")\n",
    "except Exception as e:\n",
    "    print(f\"√ó Error initializing client: {str(e)}\")\n",
    "    print(\"üí° Tip: Make sure your AI_FOUNDRY_PROJECT_ENDPOINT is set in the .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e98e282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Validating endpoint configuration...\n",
      "‚úì Endpoint looks clean: https://demopocaifoundry.services.ai.azure.com/api/projects/demoproject\n"
     ]
    }
   ],
   "source": [
    "# Validate and clean the endpoint\n",
    "print(\"üîç Validating endpoint configuration...\")\n",
    "\n",
    "if project_endpoint and '#' in project_endpoint:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Your endpoint contains a '#' character!\")\n",
    "    print(f\"   Current value: {project_endpoint}\")\n",
    "    print(\"\\n   This looks like a comment was left in your .env file.\")\n",
    "    \n",
    "    # Extract the actual endpoint (everything before the #)\n",
    "    clean_endpoint = project_endpoint.split('#')[0].strip()\n",
    "    print(f\"   Cleaned endpoint: {clean_endpoint}\")\n",
    "    \n",
    "    print(\"\\nüîß To fix permanently:\")\n",
    "    print(\"   1. Open your .env file\")\n",
    "    print(\"   2. Find the AI_FOUNDRY_PROJECT_ENDPOINT line\")\n",
    "    print(\"   3. Remove everything after and including the '#'\")\n",
    "    print(\"   4. Save the file and reload this notebook\")\n",
    "    \n",
    "    # Use the cleaned endpoint for this session\n",
    "    project_endpoint = clean_endpoint\n",
    "    print(f\"\\n‚úÖ Using cleaned endpoint for this session: {project_endpoint}\")\n",
    "    \n",
    "    # Recreate the client with the clean endpoint\n",
    "    client = AIProjectClient(\n",
    "        credential=credential,\n",
    "        endpoint=project_endpoint\n",
    "    )\n",
    "    print(\"‚úì Client recreated with cleaned endpoint\")\n",
    "else:\n",
    "    print(f\"‚úì Endpoint looks clean: {project_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77e602",
   "metadata": {},
   "source": [
    "## Create a Simple Completion\n",
    "Let's try a basic completion request:\n",
    "\n",
    "Now that we have an authenticated client, let's use it to make a chat completion request.\n",
    "The code below demonstrates how to:\n",
    "1. Get a ChatCompletionsClient from the azure-ai-inference package\n",
    "2. Use it to make a simple completion request\n",
    "\n",
    "We'll use the MODEL_DEPLOYMENT_NAME from our `.env` file, making it easy to switch between different\n",
    "deployed models without changing code. This could be an Azure OpenAI model, Microsoft model, or other providers\n",
    "that support chat completions.\n",
    "\n",
    "> Note: Make sure you have the azure-ai-inference package installed (from requirements.txt or as mentioned in [README.md](../README.md#-quick-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3774ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Step 1: Loading environment variables...\n",
      "‚úì MODEL_DEPLOYMENT_NAME: gpt-4o\n",
      "\n",
      "üîç Step 2: Checking client object...\n",
      "‚úì Client object exists: True\n",
      "‚úì Client type: <class 'azure.ai.projects._patch.AIProjectClient'>\n",
      "\n",
      "üîç Step 3: Getting OpenAI client...\n",
      "‚úì OpenAI client created: <class 'openai.lib.azure.AzureOpenAI'>\n",
      "\n",
      "üîç Step 4: Creating chat completion...\n",
      "‚úì Chat completion successful!\n",
      "\n",
      "üîç Step 5: Extracting response...\n",
      "‚úÖ Response: Maintain a balanced diet, exercise regularly, get adequate sleep, stay hydrated, manage stress, and avoid harmful substances.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "print(\"üîç Step 1: Loading environment variables...\")\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "print(f\"‚úì MODEL_DEPLOYMENT_NAME: {model_deployment_name}\")\n",
    "\n",
    "print(\"\\nüîç Step 2: Checking client object...\")\n",
    "print(f\"‚úì Client object exists: {client is not None}\")\n",
    "print(f\"‚úì Client type: {type(client)}\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nüîç Step 3: Getting OpenAI client...\")\n",
    "    aoai_client = client.get_openai_client(api_version=\"2024-10-21\")\n",
    "    print(f\"‚úì OpenAI client created: {type(aoai_client)}\")\n",
    "    \n",
    "    print(\"\\nüîç Step 4: Creating chat completion...\")\n",
    "    response = aoai_client.chat.completions.create(\n",
    "        model=model_deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"How to be healthy in one sentence?\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"‚úì Chat completion successful!\")\n",
    "    \n",
    "    print(\"\\nüîç Step 5: Extracting response...\")\n",
    "    print(f\"‚úÖ Response: {response.choices[0].message.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå An error occurred at one of the above steps:\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {str(e)}\")\n",
    "    print(f\"\\nüí° Tip: Make sure your MODEL_DEPLOYMENT_NAME ({model_deployment_name}) is correctly configured and deployed\")\n",
    "    import traceback\n",
    "    print(\"\\nüîç Full traceback:\")\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7864f9",
   "metadata": {},
   "source": [
    "## Create a simple Agent\n",
    "\n",
    "Using AI Agent Service, we can create a simple agent to answer health related questions.\n",
    "\n",
    "Let's explore Azure AI Agent Service, a powerful tool for building intelligent agents.\n",
    "\n",
    "Azure AI Agent Service is a fully managed service that helps developers build, deploy, and scale AI agents\n",
    "without managing infrastructure. It combines large language models with tools that allow agents to:\n",
    "- Answer questions using RAG (Retrieval Augmented Generation)\n",
    "- Perform actions through tool calling \n",
    "- Automate complex workflows\n",
    "\n",
    "The code below demonstrates how to:\n",
    "1. Create an agent with a code interpreter tool\n",
    "2. Create a conversation thread\n",
    "3. Send a message requesting BMI analysis \n",
    "4. Process the request and get results\n",
    "5. Save any generated visualizations to local files\n",
    "\n",
    "The agent will use the model specified in our .env file (MODEL_DEPLOYMENT_NAME) and will have access\n",
    "to a code interpreter tool for creating visualizations. This showcases how agents can combine\n",
    "natural language understanding with computational capabilities.\n",
    "\n",
    "> **Note:** Generated visualizations will be saved as PNG files in the same folder as this notebook.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb12b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verifying Project Configuration...\n",
      "Project endpoint: https://demopocaifoundry.services.ai.azure.com/api/projects/demoproject\n",
      "Model deployment: gpt-4o\n",
      "‚úì Endpoint format looks correct for Azure AI Foundry\n",
      "Client type: <class 'azure.ai.projects._patch.AIProjectClient'>\n",
      "\n",
      "üîç Additional Diagnostics...\n",
      "Testing project properties access...\n",
      "‚úì Client config available\n",
      "‚úì Endpoint parts: ['https:', '', 'demopocaifoundry.services.ai.azure.com', 'api', 'projects', 'demoproject']\n",
      "‚úì Extracted project name: demoproject\n",
      "\n",
      "üîç Step 1: Initializing Code Interpreter Tool...\n",
      "‚úì Code Interpreter Tool initialized\n",
      "\n",
      "üîç Step 2: Creating AI agent...\n",
      "Using model: gpt-4o\n",
      "Using endpoint: https://demopocaifoundry.services.ai.azure.com/api/projects/demoproject\n",
      "‚úì Agent created with ID: asst_W5kkWllnJvKDo3M8IChjWpd0\n",
      "\n",
      "üîç Step 3: Creating conversation thread...\n",
      "‚úì Thread created with ID: thread_0deaZHuAAsjC0kbQk4RdFlH9\n",
      "\n",
      "üîç Step 4: Creating message...\n",
      "‚úì Message created\n",
      "\n",
      "üîç Step 5: Processing thread run...\n",
      "‚úì Thread run completed\n",
      "\n",
      "üîç Step 6: Getting agent response...\n",
      "\n",
      "ü§ñ Assistant: The visualization shows the BMI scale ranging from 15 to 35 and highlights the four standard categories:\n",
      "\n",
      "- **Underweight (<18.5)**: Blue area\n",
      "- **Normal Weight (18.5-24.9)**: Green area\n",
      "- **Overweight (25-29.9)**: Yellow area\n",
      "- **Obese (‚â•30)**: Red area\n",
      "\n",
      "The average BMI for a US female is calculated as **22.3**, indicated by the black dashed line. As shown, this BMI falls within the **Normal Weight** category.\n",
      "üìä Visualization saved as: bmi_analysis_assistant-57yNrVqQyiyeG6GKqbTqjz.png\n",
      "\n",
      "üîç Step 7: Cleaning up...\n",
      "‚úì Agent deleted successfully\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import CodeInterpreterTool\n",
    "\n",
    "print(\"üîç Verifying Project Configuration...\")\n",
    "print(f\"Project endpoint: {project_endpoint}\")\n",
    "print(f\"Model deployment: {model_deployment_name}\")\n",
    "\n",
    "# Check if endpoint looks like an Azure AI Foundry endpoint\n",
    "if \"api.azureml.ms\" in project_endpoint or \"inference.ml.azure.com\" in project_endpoint or \"services.ai.azure.com\" in project_endpoint:\n",
    "    print(\"‚úì Endpoint format looks correct for Azure AI Foundry\")\n",
    "elif \"openai.azure.com\" in project_endpoint:\n",
    "    print(\"‚ùå This looks like an Azure OpenAI endpoint, not an Azure AI Foundry project endpoint\")\n",
    "    print(\"\\nüí° To fix this:\")\n",
    "    print(\"1. Go to https://ai.azure.com\")\n",
    "    print(\"2. Select your project\")\n",
    "    print(\"3. Go to Settings ‚Üí Project details\")\n",
    "    print(\"4. Copy the 'Project connection string' or 'Endpoint'\")\n",
    "    print(\"5. Update AI_FOUNDRY_PROJECT_ENDPOINT in your .env file\")\n",
    "    raise ValueError(\"Incorrect endpoint format - need Azure AI Foundry project endpoint\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Unknown endpoint format\")\n",
    "\n",
    "print(f\"Client type: {type(client)}\")\n",
    "\n",
    "# Additional diagnostics for agents API\n",
    "print(\"\\nüîç Additional Diagnostics...\")\n",
    "try:\n",
    "    # Try to get project properties to verify connectivity\n",
    "    print(\"Testing project properties access...\")\n",
    "    # The client should have project properties\n",
    "    if hasattr(client, 'project_url'):\n",
    "        print(f\"‚úì Project URL: {client.project_url}\")\n",
    "    if hasattr(client, '_config'):\n",
    "        print(f\"‚úì Client config available\")\n",
    "    \n",
    "    # Check subscription and resource group info from endpoint\n",
    "    import re\n",
    "    endpoint_parts = project_endpoint.split('/')\n",
    "    print(f\"‚úì Endpoint parts: {endpoint_parts}\")\n",
    "    \n",
    "    # Try to extract project name from endpoint\n",
    "    if '/projects/' in project_endpoint:\n",
    "        project_name = project_endpoint.split('/projects/')[-1].split('/')[0]\n",
    "        print(f\"‚úì Extracted project name: {project_name}\")\n",
    "    \n",
    "except Exception as diag_error:\n",
    "    print(f\"‚ö†Ô∏è Diagnostic error: {diag_error}\")\n",
    "\n",
    "try:\n",
    "    # Initialize the Code Interpreter Tool\n",
    "    print(\"\\nüîç Step 1: Initializing Code Interpreter Tool...\")\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "    print(\"‚úì Code Interpreter Tool initialized\")\n",
    "    \n",
    "    # Create an AI agent with the code interpreter tool\n",
    "    print(\"\\nüîç Step 2: Creating AI agent...\")\n",
    "    print(f\"Using model: {model_deployment_name}\")\n",
    "    print(f\"Using endpoint: {project_endpoint}\")\n",
    "    \n",
    "    agent = client.agents.create_agent(\n",
    "        model=model_deployment_name,\n",
    "        name=\"bmi-calculator\",\n",
    "        instructions=(\n",
    "            \"You are a health analyst who calculates BMI using US metrics (pounds, feet/inches). \"\n",
    "            \"Use average US female measurements: 5'4\\\" (69 inches) and 130 pounds. \"\n",
    "            \"Create a visualization showing where this BMI falls on the scale.\"\n",
    "        ),\n",
    "        tools=code_interpreter.definitions,\n",
    "        tool_resources=code_interpreter.resources,\n",
    "    )\n",
    "    print(f\"‚úì Agent created with ID: {agent.id}\")\n",
    "    \n",
    "    # Create a new conversation thread\n",
    "    print(\"\\nüîç Step 3: Creating conversation thread...\")\n",
    "    thread = client.agents.threads.create()\n",
    "    print(f\"‚úì Thread created with ID: {thread.id}\")\n",
    "    \n",
    "    # Create a message requesting BMI analysis and visualization\n",
    "    print(\"\\nüîç Step 4: Creating message...\")\n",
    "    message = client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=(\n",
    "            \"Calculate BMI for an average US female (5'4\\\", 130 lbs). \"\n",
    "            \"Create a visualization showing where this BMI falls on the standard BMI scale from 15 to 35. \"\n",
    "            \"Include the standard BMI categories (Underweight, Normal, Overweight, Obese) in the visualization.\"\n",
    "        )\n",
    "    )\n",
    "    print(\"‚úì Message created\")\n",
    "    \n",
    "    # Process the request by creating and running a thread run\n",
    "    print(\"\\nüîç Step 5: Processing thread run...\")\n",
    "    run = client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "    print(\"‚úì Thread run completed\")\n",
    "    \n",
    "    # Get the agent's response\n",
    "    print(\"\\nüîç Step 6: Getting agent response...\")\n",
    "    messages = client.agents.messages.list(thread_id=thread.id)\n",
    "    \n",
    "    # Print the assistant's response and save any images\n",
    "    for message in messages:\n",
    "        if message.role == \"assistant\":\n",
    "            # Print text content\n",
    "            for content_item in message.content:\n",
    "                if hasattr(content_item, 'text'):\n",
    "                    print(f\"\\nü§ñ Assistant: {content_item.text.value}\")\n",
    "            \n",
    "            # Save any image files using the correct API\n",
    "            for img in message.image_contents:\n",
    "                file_id = img.image_file.file_id\n",
    "                file_name = f\"bmi_analysis_{file_id}.png\"\n",
    "                \n",
    "                try:\n",
    "                    # Use the correct file saving method\n",
    "                    client.agents.files.save(file_id=file_id, file_name=file_name)\n",
    "                    print(f\"üìä Visualization saved as: {file_name}\")\n",
    "                    \n",
    "                except Exception as file_error:\n",
    "                    print(f\"‚ö†Ô∏è Could not save file {file_id}: {file_error}\")\n",
    "                    print(\"üí° You can view the file in the Azure AI Foundry portal\")\n",
    "            break\n",
    "    \n",
    "    # Cleanup by deleting the agent\n",
    "    print(\"\\nüîç Step 7: Cleaning up...\")\n",
    "    client.agents.delete_agent(agent.id)\n",
    "    print(\"‚úì Agent deleted successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå An error occurred: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    \n",
    "    if \"ResourceNotFound\" in str(type(e).__name__) or \"does not exist\" in str(e):\n",
    "        print(\"\\nüîß Troubleshooting 'Project does not exist' error:\")\n",
    "        print(\"\\n1Ô∏è‚É£ Verify your endpoint format in Azure AI Foundry:\")\n",
    "        print(\"   a. Go to https://ai.azure.com\")\n",
    "        print(\"   b. Select your project\")\n",
    "        print(\"   c. Go to Settings ‚Üí Project details\")\n",
    "        print(\"   d. Look for 'Project connection string' - it should look like:\")\n",
    "        print(\"      https://<region>.services.ai.azure.com/discovery/projects/<subscription>/<rg>/<project-name>\")\n",
    "        print(\"   OR 'Discovery service endpoint':\")\n",
    "        print(\"      https://<resource-name>.services.ai.azure.com/api/projects/<project-name>\")\n",
    "        print(f\"\\n   Your current endpoint: {project_endpoint}\")\n",
    "        \n",
    "        print(\"\\n2Ô∏è‚É£ Common endpoint issues:\")\n",
    "        print(\"   ‚Ä¢ Make sure the endpoint includes the full project path\")\n",
    "        print(\"   ‚Ä¢ Verify the project name matches exactly (case-sensitive)\")\n",
    "        print(\"   ‚Ä¢ Check if you have access to the project in the portal\")\n",
    "        \n",
    "        print(\"\\n3Ô∏è‚É£ Verify Azure AI Agents availability:\")\n",
    "        print(\"   a. In Azure AI Foundry portal, check if 'Agents' appears in your project menu\")\n",
    "        print(\"   b. Your project region must support Agents (currently limited regions)\")\n",
    "        print(\"   c. Supported regions as of Dec 2024: East US 2, Sweden Central, West US 3\")\n",
    "        print(f\"\\n   Tip: Extract region from your endpoint: {project_endpoint.split('//')[1].split('.')[0]}\")\n",
    "        \n",
    "        print(\"\\n4Ô∏è‚É£ Try alternative endpoint format:\")\n",
    "        print(\"   If your endpoint is: https://X.services.ai.azure.com/api/projects/Y\")\n",
    "        print(\"   Try the discovery format: https://X.services.ai.azure.com/discovery/projects/<sub>/<rg>/Y\")\n",
    "        print(\"   (You'll need subscription ID and resource group name from Azure Portal)\")\n",
    "        \n",
    "        print(\"\\n5Ô∏è‚É£ Verify authentication and permissions:\")\n",
    "        print(\"   ‚Ä¢ Run: az account show  (to verify logged in to correct subscription)\")\n",
    "        print(\"   ‚Ä¢ Ensure you have 'Contributor' or 'Owner' role on the AI Foundry project\")\n",
    "        print(\"   ‚Ä¢ Try running: az login --tenant <your-tenant-id> to refresh credentials\")\n",
    "        \n",
    "        print(\"\\nüìù Note: If chat completions work but agents don't, this typically means:\")\n",
    "        print(\"   - Your project exists and credentials are fine\")\n",
    "        print(\"   - But the agents API endpoint routing needs adjustment\")\n",
    "        print(\"   - Or agents feature isn't available in your project's region\")\n",
    "    else:\n",
    "        import traceback\n",
    "        print(\"\\nüîç Full traceback:\")\n",
    "        traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
